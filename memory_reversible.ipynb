{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.revunet_3D import RevUnet3D, Interpolate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mod_details(model):\n",
    "    ret = {'name' : [], 'layer' : []}\n",
    "    for name, layer in model.named_modules():\n",
    "        #print(name, layer, type(layer))\n",
    "        if name != \"\" and (isinstance(layer, torch.nn.modules.upsampling.Upsample) or isinstance(layer, torch.nn.Conv3d) or isinstance(layer, torch.nn.ReLU) or isinstance(layer, torch.nn.GroupNorm) or isinstance(layer, torch.nn.MaxPool3d)):\n",
    "            ret['name'].append(name)\n",
    "            ret['layer'].append(layer)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inchan = 1\n",
    "chanscale = 32\n",
    "chans = [i//chanscale for i in [64, 128, 256, 512]]\n",
    "outsize = 12\n",
    "interp = (512,512,198)\n",
    "mod = RevUnet3D(inchan, chans, outsize, interp)\n",
    "\n",
    "layers = get_mod_details(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations_shapes(layers, x):\n",
    "    no_rev_shapes = [x.shape]\n",
    "    with torch.no_grad():\n",
    "        for n, l in zip(layers['name'], layers['layer']):\n",
    "            print(n)\n",
    "            if 'reversible' not in n:\n",
    "                x = l(x)\n",
    "                shapes.append(x.shape)\n",
    "                \n",
    "    return shapes\n",
    "\n",
    "def get_activations_shapes_as_dict(layers, x):\n",
    "    shapes = {'input':x.shape}\n",
    "    with torch.no_grad():\n",
    "        for n, l in zip(layers['name'], layers['layer']):\n",
    "            if 'reversible' not in n:\n",
    "                x = l(x)\n",
    "                shapes[n] = x.shape\n",
    "            else:\n",
    "                x1, x2 = torch.split(x, x.shape[1]//2, dim = 1)\n",
    "                y1 = l(x1) + x2\n",
    "                shapes[n] = y1.shape\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/themyr/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.random.rand(1,1,256,256,99)).float()\n",
    "acts = get_activations_shapes_as_dict(layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_cosumption(shapes, float_types='float'):\n",
    "    m = 0\n",
    "    all_types = {'float':4, 'double':8, 'half':2}\n",
    "    for s in shapes:\n",
    "        m += np.prod(s)*all_types[float_types]\n",
    "        print(s, np.prod(s)*all_types[float_types])\n",
    "    return m\n",
    "\n",
    "def forward_memory_cosumption_with_peak(shapes, float_types='float'):\n",
    "    cur_m = 0\n",
    "    max_m = 0\n",
    "    all_types = {'float':4, 'double':8, 'half':2}\n",
    "    \n",
    "    enc, dec = -1, -1\n",
    "    for k in list(shapes.keys()):\n",
    "        s = shapes[k]\n",
    "        if 'reversible' not in k:\n",
    "            cur_m += np.prod(s)*all_types[float_types]\n",
    "            max_m += np.prod(s)*all_types[float_types]\n",
    "        elif 'encoders' in k:\n",
    "            tmp_enc = int(k[9])\n",
    "            if tmp_enc == enc:\n",
    "                tmp_max_m += np.prod(s)*all_types[float_types]\n",
    "                if max_m < tmp_max_m:\n",
    "                    max_m = tmp_max_m\n",
    "            else:\n",
    "                enc = tmp_enc\n",
    "                tmp_max_m = cur_m + np.prod(s)*all_types[float_types]\n",
    "                if max_m < tmp_max_m:\n",
    "                    max_m = tmp_max_m\n",
    "            \n",
    "                \n",
    "        \n",
    "        #print(s, np.prod(s)*all_types[float_types])\n",
    "    return cur_m, max_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flt(t):\n",
    "    return {'float':4, 'double':8, 'half':2}[t]\n",
    "\n",
    "def model_memory(mod, floatt = 'float'):\n",
    "    return sum(p.numel()*flt(floatt) for p in mod.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_byte(v):\n",
    "    units = {'Bytes':1,'KB':1e-3, 'MB':1e-6, 'GB':1e-9}\n",
    "    tmp = 'Bytes'\n",
    "    for k in list(units.keys()):\n",
    "        if int(v*units[k]) == 0:\n",
    "            return v*units[tmp], tmp\n",
    "        tmp = k\n",
    "    return v*units[tmp], tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.5949921280000003, 'GB')\n",
      "(2.7507056640000003, 'GB')\n"
     ]
    }
   ],
   "source": [
    "cur_m, max_m = memory_cosumption_with_peak(acts)\n",
    "print(convert_byte(cur_m))\n",
    "print(convert_byte(max_m))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mod = mod.cuda()\n",
    "x = x.cuda()\n",
    "y = mod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154.464, 'KB')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_byte(model_memory(mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_mem(y,floatt = 'float'):\n",
    "    return np.prod(y.shape)*flt(floatt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(np.random.rand(1,12,512,512,198)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.491416576, 'GB')\n"
     ]
    }
   ],
   "source": [
    "print(convert_byte(labels_mem(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7194, 0.5986, 0.1094, 0.5060, 0.2073],\n",
      "          [0.1055, 0.8037, 0.7823, 0.4362, 0.9706],\n",
      "          [0.4120, 0.6327, 0.2057, 0.3950, 0.2494],\n",
      "          [0.3431, 0.4298, 0.3011, 0.4617, 0.9267],\n",
      "          [0.9172, 0.5996, 0.5468, 0.7262, 0.8042]],\n",
      "\n",
      "         [[0.7219, 0.8398, 0.0785, 0.7518, 0.7601],\n",
      "          [0.5366, 0.5807, 0.0706, 0.1895, 0.7764],\n",
      "          [0.7727, 0.6994, 0.3189, 0.9119, 0.2093],\n",
      "          [0.5298, 0.3085, 0.1669, 0.7628, 0.6441],\n",
      "          [0.7853, 0.8312, 0.9386, 0.2036, 0.5099]]]])\n",
      "4\n",
      "tensor([[[1, 1, 0, 1, 1],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 0],\n",
      "         [1, 0, 0, 1, 0],\n",
      "         [0, 1, 1, 0, 0]]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = torch.from_numpy(np.random.rand(1,2,5,5)).float()\n",
    "print(a)\n",
    "print(a.element_size())\n",
    "print(torch.argmax(a,1))\n",
    "print(torch.argmax(a,1).short().element_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6788333333333333\n",
      "0.020086617988656547\n"
     ]
    }
   ],
   "source": [
    "unet = [0.703,0.694,0.652,0.666,0.698,0.660]\n",
    "rev = [0.698, 0.722, 0.697, 0.702, 0.706, 0.696]\n",
    "\n",
    "print(np.mean(unet))\n",
    "print(np.std(unet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103.809024, 'MB')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_byte(np.prod(x.shape)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "104857600 104857600\n"
     ]
    }
   ],
   "source": [
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))\n",
    "x = x.cuda().detach()\n",
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430074880 312477184\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [1] and input of shape [4, 2, 256, 256, 99]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-693a253046e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         return F.group_norm(\n\u001b[0;32m--> 246\u001b[0;31m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2110\u001b[0m         + list(input.size()[2:]))\n\u001b[1;32m   2111\u001b[0m     return torch.group_norm(input, num_groups, weight, bias, eps,\n\u001b[0;32m-> 2112\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [1] and input of shape [4, 2, 256, 256, 99]"
     ]
    }
   ],
   "source": [
    "L1 = layers['layer'][0].cuda()\n",
    "L2 = layers['layer'][1].cuda()\n",
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))\n",
    "x = L1(x)\n",
    "x = L2(x)\n",
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311427072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "103809024 + 207618048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3d(1, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers['layer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
