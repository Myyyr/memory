{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.unet_3D import unet_3D\n",
    "from models.unetUtils import Pad\n",
    "import numpy as np\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mod_details(model):\n",
    "    ret = {'name' : [], 'layer' : []}\n",
    "    for name, layer in model.named_modules():\n",
    "        #print(name, layer, type(layer))\n",
    "        #print(name, layer)\n",
    "        if name != \"\" and (isinstance(layer, torch.nn.modules.upsampling.Upsample) or isinstance(layer, torch.nn.Conv3d) or isinstance(layer, torch.nn.ReLU) or isinstance(layer, torch.nn.GroupNorm) or isinstance(layer, torch.nn.MaxPool3d) or isinstance(layer, models.unetUtils.Pad)):\n",
    "            ret['name'].append(name)\n",
    "            ret['layer'].append(layer)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/themyr/these/memory/models/networks_other.py:42: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
      "/home/themyr/these/memory/models/networks_other.py:46: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(m.weight.data, 1.0, 0.02)\n",
      "/home/themyr/these/memory/models/networks_other.py:47: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias.data, 0.0)\n"
     ]
    }
   ],
   "source": [
    "inchan = 1\n",
    "chanscale = 32\n",
    "chans = [i//chanscale for i in [64, 128, 256, 512, 1024]]\n",
    "outsize = 12\n",
    "interp = (512,512,198)\n",
    "mod = unet_3D(chans, n_classes=outsize, in_channels=inchan, interpolation = interp)\n",
    "\n",
    "layers = get_mod_details(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': ['conv1.conv1',\n",
       "  'conv1.relu1',\n",
       "  'conv1.conv2',\n",
       "  'conv1.relu2',\n",
       "  'maxpool1',\n",
       "  'conv2.conv1',\n",
       "  'conv2.relu1',\n",
       "  'conv2.conv2',\n",
       "  'conv2.relu2',\n",
       "  'maxpool2',\n",
       "  'conv3.conv1',\n",
       "  'conv3.relu1',\n",
       "  'conv3.conv2',\n",
       "  'conv3.relu2',\n",
       "  'maxpool3',\n",
       "  'conv4.conv1',\n",
       "  'conv4.relu1',\n",
       "  'conv4.conv2',\n",
       "  'conv4.relu2',\n",
       "  'maxpool4',\n",
       "  'center.conv1',\n",
       "  'center.relu1',\n",
       "  'center.conv2',\n",
       "  'center.relu2',\n",
       "  'up_concat4.up',\n",
       "  'up_concat4.pad',\n",
       "  'up_concat4.conv.conv1',\n",
       "  'up_concat4.conv.relu1',\n",
       "  'up_concat4.conv.conv2',\n",
       "  'up_concat4.conv.relu2',\n",
       "  'up_concat3.up',\n",
       "  'up_concat3.pad',\n",
       "  'up_concat3.conv.conv1',\n",
       "  'up_concat3.conv.relu1',\n",
       "  'up_concat3.conv.conv2',\n",
       "  'up_concat3.conv.relu2',\n",
       "  'up_concat2.up',\n",
       "  'up_concat2.pad',\n",
       "  'up_concat2.conv.conv1',\n",
       "  'up_concat2.conv.relu1',\n",
       "  'up_concat2.conv.conv2',\n",
       "  'up_concat2.conv.relu2',\n",
       "  'up_concat1.up',\n",
       "  'up_concat1.pad',\n",
       "  'up_concat1.conv.conv1',\n",
       "  'up_concat1.conv.relu1',\n",
       "  'up_concat1.conv.conv2',\n",
       "  'up_concat1.conv.relu2',\n",
       "  'final',\n",
       "  'interpolation'],\n",
       " 'layer': [Conv3d(1, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(2, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False),\n",
       "  Conv3d(2, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False),\n",
       "  Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False),\n",
       "  Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False),\n",
       "  Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear),\n",
       "  Pad(),\n",
       "  Conv3d(48, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear),\n",
       "  Pad(),\n",
       "  Conv3d(24, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(8, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear),\n",
       "  Pad(),\n",
       "  Conv3d(12, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(4, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Upsample(scale_factor=(2.0, 2.0, 2.0), mode=trilinear),\n",
       "  Pad(),\n",
       "  Conv3d(6, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(2, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
       "  ReLU(inplace=True),\n",
       "  Conv3d(2, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1)),\n",
       "  Upsample(size=(512, 512, 198), mode=trilinear)]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations_shapes(layers, x):\n",
    "    no_rev_shapes = [x.shape]\n",
    "    with torch.no_grad():\n",
    "        for n, l in zip(layers['name'], layers['layer']):\n",
    "            print(n)\n",
    "            x = l(x)\n",
    "            shapes.append(x.shape)\n",
    "                \n",
    "    return shapes\n",
    "\n",
    "def get_activations_shapes_as_dict(layers, x):\n",
    "    shapes = {'input':x.shape}\n",
    "    tmp = []\n",
    "    up = -1\n",
    "    with torch.no_grad():\n",
    "        for n, l in zip(layers['name'], layers['layer']):\n",
    "            print(n)\n",
    "            if 'max' in n:\n",
    "                tmp.append(x)\n",
    "                x = l(x)\n",
    "                shapes[n] = x.shape\n",
    "            elif 'pad' in n:\n",
    "                inputs1 = tmp[up]\n",
    "                offset = x.size()[2] - inputs1.size()[2]\n",
    "                padding = 2 * [offset // 2, offset // 2, 0]\n",
    "                x, y = l(inputs1, x, padding)\n",
    "                x = torch.cat([x,y],1)\n",
    "                up -= 1    \n",
    "            else:\n",
    "                x = l(x)\n",
    "                shapes[n] = x.shape\n",
    "    return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.conv1\n",
      "conv1.relu1\n",
      "conv1.conv2\n",
      "conv1.relu2\n",
      "maxpool1\n",
      "conv2.conv1\n",
      "conv2.relu1\n",
      "conv2.conv2\n",
      "conv2.relu2\n",
      "maxpool2\n",
      "conv3.conv1\n",
      "conv3.relu1\n",
      "conv3.conv2\n",
      "conv3.relu2\n",
      "maxpool3\n",
      "conv4.conv1\n",
      "conv4.relu1\n",
      "conv4.conv2\n",
      "conv4.relu2\n",
      "maxpool4\n",
      "center.conv1\n",
      "center.relu1\n",
      "center.conv2\n",
      "center.relu2\n",
      "up_concat4.up\n",
      "up_concat4.pad\n",
      "up_concat4.conv.conv1\n",
      "up_concat4.conv.relu1\n",
      "up_concat4.conv.conv2\n",
      "up_concat4.conv.relu2\n",
      "up_concat3.up\n",
      "up_concat3.pad\n",
      "up_concat3.conv.conv1\n",
      "up_concat3.conv.relu1\n",
      "up_concat3.conv.conv2\n",
      "up_concat3.conv.relu2\n",
      "up_concat2.up\n",
      "up_concat2.pad\n",
      "up_concat2.conv.conv1\n",
      "up_concat2.conv.relu1\n",
      "up_concat2.conv.conv2\n",
      "up_concat2.conv.relu2\n",
      "up_concat1.up\n",
      "up_concat1.pad\n",
      "up_concat1.conv.conv1\n",
      "up_concat1.conv.relu1\n",
      "up_concat1.conv.conv2\n",
      "up_concat1.conv.relu2\n",
      "final\n",
      "interpolation\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(np.random.rand(1,1,256,256,99)).float()\n",
    "acts = get_activations_shapes_as_dict(layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_cosumption(shapes, float_types='float'):\n",
    "    m = 0\n",
    "    all_types = {'float':4, 'double':8, 'half':2}\n",
    "    for s in shapes:\n",
    "        m += np.prod(s)*all_types[float_types]\n",
    "        print(s, np.prod(s)*all_types[float_types])\n",
    "    return m\n",
    "\n",
    "def forward_memory_cosumption_with_peak(shapes, float_types='float'):\n",
    "    cur_m = 0\n",
    "    all_types = {'float':4, 'double':8, 'half':2}\n",
    "    \n",
    "    enc, dec = -1, -1\n",
    "    for k in list(shapes.keys()):\n",
    "        s = shapes[k]\n",
    "        cur_m += np.prod(s)*all_types[float_types]\n",
    "\n",
    "    return cur_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flt(t):\n",
    "    return {'float':4, 'double':8, 'half':2}[t]\n",
    "\n",
    "def model_memory(mod, floatt = 'float'):\n",
    "    return sum(p.numel()*flt(floatt) for p in mod.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_byte(v):\n",
    "    units = {'Bytes':1,'KB':1e-3, 'MB':1e-6, 'GB':1e-9}\n",
    "    tmp = 'Bytes'\n",
    "    for k in list(units.keys()):\n",
    "        if int(v*units[k]) == 0:\n",
    "            return v*units[tmp], tmp\n",
    "        tmp = k\n",
    "    return v*units[tmp], tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.5233136640000002, 'GB')\n"
     ]
    }
   ],
   "source": [
    "cur_m = forward_memory_cosumption_with_peak(acts)\n",
    "print(convert_byte(cur_m))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mod = mod.cuda()\n",
    "x = x.cuda()\n",
    "y = mod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154.464, 'KB')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_byte(model_memory(mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_mem(y,floatt = 'float'):\n",
    "    return np.prod(y.shape)*flt(floatt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.from_numpy(np.random.rand(1,12,512,512,198)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.491416576, 'GB')\n"
     ]
    }
   ],
   "source": [
    "print(convert_byte(labels_mem(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.7194, 0.5986, 0.1094, 0.5060, 0.2073],\n",
      "          [0.1055, 0.8037, 0.7823, 0.4362, 0.9706],\n",
      "          [0.4120, 0.6327, 0.2057, 0.3950, 0.2494],\n",
      "          [0.3431, 0.4298, 0.3011, 0.4617, 0.9267],\n",
      "          [0.9172, 0.5996, 0.5468, 0.7262, 0.8042]],\n",
      "\n",
      "         [[0.7219, 0.8398, 0.0785, 0.7518, 0.7601],\n",
      "          [0.5366, 0.5807, 0.0706, 0.1895, 0.7764],\n",
      "          [0.7727, 0.6994, 0.3189, 0.9119, 0.2093],\n",
      "          [0.5298, 0.3085, 0.1669, 0.7628, 0.6441],\n",
      "          [0.7853, 0.8312, 0.9386, 0.2036, 0.5099]]]])\n",
      "4\n",
      "tensor([[[1, 1, 0, 1, 1],\n",
      "         [1, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 0],\n",
      "         [1, 0, 0, 1, 0],\n",
      "         [0, 1, 1, 0, 0]]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = torch.from_numpy(np.random.rand(1,2,5,5)).float()\n",
    "print(a)\n",
    "print(a.element_size())\n",
    "print(torch.argmax(a,1))\n",
    "print(torch.argmax(a,1).short().element_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6788333333333333\n",
      "0.020086617988656547\n"
     ]
    }
   ],
   "source": [
    "unet = [0.703,0.694,0.652,0.666,0.698,0.660]\n",
    "rev = [0.698, 0.722, 0.697, 0.702, 0.706, 0.696]\n",
    "\n",
    "print(np.mean(unet))\n",
    "print(np.std(unet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103.809024, 'MB')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_byte(np.prod(x.shape)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "104857600 104857600\n"
     ]
    }
   ],
   "source": [
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))\n",
    "x = x.cuda().detach()\n",
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430074880 312477184\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [1] and input of shape [4, 2, 256, 256, 99]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-693a253046e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         return F.group_norm(\n\u001b[0;32m--> 246\u001b[0;31m             input, self.num_groups, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flam/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2110\u001b[0m         + list(input.size()[2:]))\n\u001b[1;32m   2111\u001b[0m     return torch.group_norm(input, num_groups, weight, bias, eps,\n\u001b[0;32m-> 2112\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected weight to be a vector of size equal to the number of channels in input, but got weight of shape [1] and input of shape [4, 2, 256, 256, 99]"
     ]
    }
   ],
   "source": [
    "L1 = layers['layer'][0].cuda()\n",
    "L2 = layers['layer'][1].cuda()\n",
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))\n",
    "x = L1(x)\n",
    "x = L2(x)\n",
    "print((torch.cuda.max_memory_allocated()), ((torch.cuda.memory_allocated())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311427072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "103809024 + 207618048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv3d(1, 2, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers['layer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
